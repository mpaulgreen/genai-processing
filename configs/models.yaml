# Models configuration for GenAI Processing Layer
# This file configures different LLM providers and their parameters

default_provider: "claude"

providers:
  claude:
    provider: "anthropic"
    endpoint: "https://api.anthropic.com/v1/messages"
    api_key: "${ANTHROPIC_API_KEY:-placeholder-key}"
    model_name: "claude-3-5-sonnet-20241022"
    max_tokens: 4000
    temperature: 0.1
    timeout: "60s"
    retry_attempts: 3
    retry_delay: "1s"
    input_adapter: "claude_input_adapter"
    output_parser: "claude_extractor"
    prompt_formatter: "claude_formatter"
    parameters:
      system: "You are an OpenShift audit query specialist."
      max_tokens: "4000"
      temperature: "0.1"

  openai:
    provider: "openai"
    endpoint: "https://api.openai.com/v1/chat/completions"
    api_key: "${OPENAI_API_KEY:-placeholder-key}"
    model_name: "gpt-4"
    max_tokens: 4000
    temperature: 0.1
    timeout: "60s"
    retry_attempts: 3
    retry_delay: "1s"
    input_adapter: "openai_input_adapter"
    output_parser: "openai_extractor"
    prompt_formatter: "openai_formatter"
    parameters:
      system: "You are an OpenShift audit query specialist."
      max_tokens: "4000"
      temperature: "0.1"

  local_llama:
    provider: "ollama"
    endpoint: "http://localhost:11434"
    api_key: ""
    model_name: "llama3.1:8b"
    max_tokens: 4000
    temperature: 0.1
    timeout: "60s"
    retry_attempts: 3
    retry_delay: "1s"
    input_adapter: "ollama_input_adapter"
    output_parser: "generic_extractor"
    prompt_formatter: "generic_formatter"
    parameters:
      system: "You are an OpenShift audit query specialist."
      max_tokens: "4000"
      temperature: "0.1"

  user_model:
    provider: "generic"
    endpoint: "${USER_MODEL_ENDPOINT:-http://localhost:8080}"
    api_key: "${USER_MODEL_API_KEY:-}"
    model_name: "custom-model"
    max_tokens: 4000
    temperature: 0.1
    timeout: "60s"
    retry_attempts: 3
    retry_delay: "1s"
    input_adapter: "generic_input_adapter"
    output_parser: "generic_extractor"
    prompt_formatter: "generic_formatter"
    parameters:
      system: "You are an OpenShift audit query specialist."
      max_tokens: "4000"
      temperature: "0.1"
